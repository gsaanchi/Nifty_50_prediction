{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubxam/projects/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from typing import Any, Literal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import nsepython as nse\n",
    "import logging\n",
    "import duckdb\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "from huggingface_hub.inference_api import InferenceApi\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubxam/projects/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "universe = \"nifty_500\"\n",
    "news_url = \"https://www.google.com/finance/quote\"\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0\"\n",
    "}\n",
    "token = os.getenv(\"hf_api_key\")\n",
    "# sentiment_model_1 = InferenceApi(\"ProsusAI/finbert\", token=token)\n",
    "sentiment_model = InferenceApi(\n",
    "    \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\", token=token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of stocks in the universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tickers() -> None:\n",
    "    \"\"\"\n",
    "    Fetches the tickers for the specified Nifty index.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the tickers and company names.\n",
    "    \"\"\"\n",
    "\n",
    "    # check if a directory datasets exists in root folder if not then create it\n",
    "    if not os.path.exists(\"./datasets\"):\n",
    "        os.makedirs(\"./datasets\")\n",
    "\n",
    "    # Dictionary to store the URLs for the different Nifty indices\n",
    "    tickers_url_dict: dict = {\n",
    "        \"nifty_500\": \"https://archives.nseindia.com/content/indices/ind_nifty500list.csv\",\n",
    "        \"nifty_200\": \"https://archives.nseindia.com/content/indices/ind_nifty200list.csv\",\n",
    "        \"nifty_100\": \"https://archives.nseindia.com/content/indices/ind_nifty100list.csv\",\n",
    "        \"nifty_50\": \"https://archives.nseindia.com/content/indices/ind_nifty50list.csv\",\n",
    "    }\n",
    "\n",
    "    logging.info(f\"Downloading Tickers List for {list(tickers_url_dict.keys())}\")\n",
    "\n",
    "    for index_name in tickers_url_dict.keys():\n",
    "        try:\n",
    "            ticker_list_url = tickers_url_dict[index_name]\n",
    "            ticker_list_df = pd.read_csv(ticker_list_url)\n",
    "            ticker_list_df.to_csv(f\"./datasets/{index_name}.csv\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error fetching tickers for {index_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 17:26:35,788 - INFO - Downloading Tickers List for ['nifty_500', 'nifty_200', 'nifty_100', 'nifty_50']\n"
     ]
    }
   ],
   "source": [
    "fetch_tickers()\n",
    "tickers_df = pd.read_csv(f\"./datasets/{universe}.csv\")\n",
    "tickers_list = list(tickers_df[\"Symbol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch News Data and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_content(\n",
    "    ticker: str,\n",
    ") -> tuple[None, None, None] | tuple[str, BeautifulSoup, dict]:\n",
    "    _ticker: str = ticker + \":NSE\"\n",
    "    url = f\"{news_url}/{_ticker}\"\n",
    "    logging.debug(f\"Fetching data for {ticker} from {url}\")\n",
    "    try:\n",
    "        response: requests.Response = requests.get(url, headers=header)\n",
    "        soup: BeautifulSoup = BeautifulSoup(response.content, \"lxml\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None, None, None\n",
    "    meta: dict = nse.nse_eq(ticker)\n",
    "    return ticker, soup, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_relative_date(date_string) -> None | datetime:\n",
    "    now = datetime.now()\n",
    "    parts = date_string.split()\n",
    "\n",
    "    if len(parts) != 2 and len(parts) != 3:\n",
    "        return None\n",
    "\n",
    "    value = int(parts[0]) if parts[0] != \"a\" else 1\n",
    "    unit = parts[1]\n",
    "\n",
    "    if unit.startswith(\"minute\"):\n",
    "        return now - timedelta(minutes=value)\n",
    "    elif unit.startswith(\"hour\"):\n",
    "        return now - timedelta(hours=value)\n",
    "    elif unit.startswith(\"day\"):\n",
    "        return now - timedelta(days=value)\n",
    "    elif unit.startswith(\"week\"):\n",
    "        return now - timedelta(weeks=value)\n",
    "    elif unit.startswith(\"month\"):\n",
    "        return now - relativedelta(months=value)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_article_fetch(\n",
    "    ticker, soup\n",
    ") -> tuple[list, Literal[True]] | tuple[list, Literal[False]]:\n",
    "    article_data = []\n",
    "    news_articles: list = soup.select(\"div.z4rs2b\")\n",
    "\n",
    "    if not news_articles:\n",
    "        logging.warning(f\"No news found for {ticker}\")\n",
    "        return article_data, True\n",
    "\n",
    "    ticker_articles_counter = 0\n",
    "\n",
    "    for link in news_articles:\n",
    "        art_title: str = link.select_one(\"div.Yfwt5\").text.strip().replace(\"\\n\", \"\")\n",
    "        date_posted_str: str = link.select_one(\"div.Adak\").text\n",
    "        date_posted: str = parse_relative_date(date_posted_str).strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        source: str = link.select_one(\"div.sfyJob\").text\n",
    "        article_link: str = link.select_one(\"a\").get(\"href\")\n",
    "\n",
    "        article_data.append([ticker, art_title, date_posted, source, article_link])\n",
    "        ticker_articles_counter += 1\n",
    "\n",
    "    logging.debug(f\"No of articles: {ticker_articles_counter} for {ticker}\")\n",
    "    return article_data, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_meta_fetch(ticker: str, meta: dict) -> list:\n",
    "    try:\n",
    "        sector: str = meta[\"industryInfo\"][\"macro\"]\n",
    "        industry: str = meta[\"industryInfo\"][\"industry\"]\n",
    "        mCap: float = round(\n",
    "            (meta[\"priceInfo\"][\"previousClose\"] * meta[\"securityInfo\"][\"issuedSize\"])\n",
    "            / 1e9,\n",
    "            2,\n",
    "        )\n",
    "        companyName: str = meta[\"info\"][\"companyName\"]\n",
    "    except KeyError as e:\n",
    "        logging.warning(f\"Error fetching metadata for {ticker}: {e}\")\n",
    "        sector = industry = mCap = companyName = np.nan\n",
    "    return [ticker, sector, industry, mCap, companyName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticker(ticker: str) -> dict[str, Any]:\n",
    "    try:\n",
    "        ticker, soup, meta = get_url_content(ticker)\n",
    "        article_data, no_news = ticker_article_fetch(ticker, soup)\n",
    "        if no_news:\n",
    "            logging.info(f\"Skipping meta check for {ticker}\")\n",
    "            return {\n",
    "                \"ticker\": ticker,\n",
    "                \"article_data\": [],\n",
    "                \"ticker_meta\": None,\n",
    "                \"unavailable\": True,\n",
    "            }\n",
    "        ticker_meta = ticker_meta_fetch(ticker, meta)\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"article_data\": article_data,\n",
    "            \"ticker_meta\": ticker_meta,\n",
    "            \"unavailable\": False,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error processing {ticker}: {e}\")\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"article_data\": [],\n",
    "            \"ticker_meta\": None,\n",
    "            \"unavailable\": True,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/502 [00:00<?, ?it/s]2024-08-30 17:26:50,047 - WARNING - Error processing ABBOTINDIA: 'NoneType' object has no attribute 'strftime'\n",
      " 15%|█▍        | 75/502 [00:43<03:33,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please use nse_fno() function to reduce latency.\n",
      "Please use nse_fno() function to reduce latency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 17:28:11,080 - WARNING - No news found for DUMMYRAYMD\n",
      "2024-08-30 17:28:11,081 - INFO - Skipping meta check for DUMMYRAYMD\n",
      "2024-08-30 17:28:11,081 - INFO - Skipping meta check for DUMMYRAYMD\n",
      "2024-08-30 17:28:14,983 - WARNING - No news found for DUMMYSANOF\n",
      "2024-08-30 17:28:14,983 - INFO - Skipping meta check for DUMMYSANOF\n",
      "2024-08-30 17:28:37,770 - WARNING - Error fetching data for BIOCON: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: /finance/quote/BIOCON:NSE (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x12c7702b0>, 'Connection to www.google.com timed out. (connect timeout=None)'))\n",
      "2024-08-30 17:28:37,770 - WARNING - Error processing None: 'NoneType' object has no attribute 'select'\n",
      " 63%|██████▎   | 314/502 [03:05<01:55,  1.63it/s] 2024-08-30 17:29:50,112 - WARNING - Error processing MARUTI: 'NoneType' object has no attribute 'strftime'\n",
      " 73%|███████▎  | 364/502 [03:34<01:42,  1.34it/s]2024-08-30 17:30:19,273 - WARNING - No news found for PPLPHARMA\n",
      "2024-08-30 17:30:19,274 - INFO - Skipping meta check for PPLPHARMA\n",
      " 78%|███████▊  | 393/502 [03:50<01:02,  1.73it/s]2024-08-30 17:30:36,054 - WARNING - No news found for RELIANCE\n",
      "2024-08-30 17:30:36,055 - INFO - Skipping meta check for RELIANCE\n",
      "100%|██████████| 502/502 [04:56<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "ticker_data = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=mp.cpu_count()) as executor:\n",
    "\n",
    "    futures = [executor.submit(process_ticker, ticker) for ticker in tickers_list]\n",
    "\n",
    "    ticker_data = [future.result() for future in tqdm(futures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = []\n",
    "ticker_meta = []\n",
    "unavailable_tickers = []\n",
    "\n",
    "for result in ticker_data:\n",
    "    if result[\"unavailable\"]:\n",
    "        unavailable_tickers.append(result[\"ticker\"])\n",
    "    else:\n",
    "        article_data.extend(result[\"article_data\"])\n",
    "        ticker_meta.append(result[\"ticker_meta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 17:31:48,917 - INFO - No news data available for: ['ABBOTINDIA', None, 'DUMMYRAYMD', 'DUMMYSANOF', 'MARUTI', 'PPLPHARMA', 'RELIANCE']\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"No news data available for: {unavailable_tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>source</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Stocks to Watch: Jio Financial Services, ICICI...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>mint</td>\n",
       "      <td>https://www.livemint.com/market/stock-market-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Brokerage Radar: United Spirits, Zydus Life ba...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>Moneycontrol</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>डबल अपग्रेड हुआ ये Pharma Stock, ब्रोकरेज सुपर...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>Zee Business</td>\n",
       "      <td>https://www.zeebiz.com/hindi/stock-markets/sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Hot stocks: Brokerage view on L&amp;T Finance, Ind...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>The Economic Times</td>\n",
       "      <td>https://m.economictimes.com/markets/stocks/new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>ECLERX</td>\n",
       "      <td>This mid-cap IT party is getting lit; NIIT, Da...</td>\n",
       "      <td>2024-08-27 17:31:40</td>\n",
       "      <td>Moneycontrol</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker                                           headline  \\\n",
       "2145  ZYDUSLIFE  Stocks to Watch: Jio Financial Services, ICICI...   \n",
       "2146  ZYDUSLIFE  Brokerage Radar: United Spirits, Zydus Life ba...   \n",
       "2147  ZYDUSLIFE  डबल अपग्रेड हुआ ये Pharma Stock, ब्रोकरेज सुपर...   \n",
       "2148  ZYDUSLIFE  Hot stocks: Brokerage view on L&T Finance, Ind...   \n",
       "2149     ECLERX  This mid-cap IT party is getting lit; NIIT, Da...   \n",
       "\n",
       "              date_posted              source  \\\n",
       "2145  2024-08-28 17:31:40                mint   \n",
       "2146  2024-08-28 17:31:40        Moneycontrol   \n",
       "2147  2024-08-28 17:31:40        Zee Business   \n",
       "2148  2024-08-28 17:31:40  The Economic Times   \n",
       "2149  2024-08-27 17:31:40        Moneycontrol   \n",
       "\n",
       "                                           article_link  \n",
       "2145  https://www.livemint.com/market/stock-market-n...  \n",
       "2146  https://www.moneycontrol.com/news/business/bro...  \n",
       "2147  https://www.zeebiz.com/hindi/stock-markets/sto...  \n",
       "2148  https://m.economictimes.com/markets/stocks/new...  \n",
       "2149  https://www.moneycontrol.com/news/business/mar...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.DataFrame(\n",
    "    article_data,\n",
    "    columns=[\"ticker\", \"headline\", \"date_posted\", \"source\", \"article_link\"],\n",
    ")\n",
    "article_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_meta_df = pd.DataFrame(\n",
    "    ticker_meta,\n",
    "    columns=[\"ticker\", \"sector\", \"industry\", \"marketCap\", \"companyName\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 17:31:53,636 - INFO - Performing Sentiment Analysis\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Performing Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list = article_df.headline.astype(str).tolist()\n",
    "sentiment_scores = sentiment_model(article_df.headline.astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline: Most bonus shares — These Nifty companies have issued free stock the most times; do you own any?\n",
      "sentiment score: \n",
      "      neutral: 0.9998911619186401\n",
      "      negative: 6.778783426852897e-05\n",
      "      positive: 4.1013929148903117e-05\n"
     ]
    }
   ],
   "source": [
    "index = 103\n",
    "print(f\"headline: {articles_list[index]}\")\n",
    "print(\n",
    "    f\"\"\"sentiment score: \n",
    "      {sentiment_scores[index][0]['label']}: {sentiment_scores[index][0]['score']}\n",
    "      {sentiment_scores[index][1]['label']}: {sentiment_scores[index][1]['score']}\n",
    "      {sentiment_scores[index][2]['label']}: {sentiment_scores[index][2]['score']}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(headline: list[str]) -> pd.DataFrame:\n",
    "\n",
    "    results: list = sentiment_model(headline)\n",
    "\n",
    "    # Initialize an empty list to hold the flattened data\n",
    "    flattened_data: list = []\n",
    "\n",
    "    for list_item in results:\n",
    "        score_dict = dict()\n",
    "        for dict_item in list_item:\n",
    "            sentiment = dict_item[\"label\"]\n",
    "            sentiment_score = dict_item[\"score\"]\n",
    "            score_dict[sentiment] = sentiment_score\n",
    "        flattened_data.append(score_dict)\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    # Calculate the compound score\n",
    "    df.loc[:, \"compound\"] = df.loc[:, \"positive\"] - df.loc[:, \"negative\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores_df = perform_sentiment_analysis(\n",
    "    article_df.headline.astype(str).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999497</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.999313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.998983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>-0.993407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.999398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive   neutral  negative  compound\n",
       "0  0.999497  0.000319  0.000184  0.999313\n",
       "1  0.999225  0.000534  0.000241  0.998983\n",
       "2  0.000440  0.005712  0.993847 -0.993407\n",
       "3  0.999605  0.000188  0.000207  0.999398\n",
       "4  0.000041  0.999891  0.000068 -0.000027"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.merge(\n",
    "    article_df, sentiment_scores_df, left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>source</th>\n",
       "      <th>article_link</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Stocks to Watch: Jio Financial Services, ICICI...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>mint</td>\n",
       "      <td>https://www.livemint.com/market/stock-market-n...</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Brokerage Radar: United Spirits, Zydus Life ba...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>Moneycontrol</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/bro...</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.999211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>डबल अपग्रेड हुआ ये Pharma Stock, ब्रोकरेज सुपर...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>Zee Business</td>\n",
       "      <td>https://www.zeebiz.com/hindi/stock-markets/sto...</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "      <td>Hot stocks: Brokerage view on L&amp;T Finance, Ind...</td>\n",
       "      <td>2024-08-28 17:31:40</td>\n",
       "      <td>The Economic Times</td>\n",
       "      <td>https://m.economictimes.com/markets/stocks/new...</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>ECLERX</td>\n",
       "      <td>This mid-cap IT party is getting lit; NIIT, Da...</td>\n",
       "      <td>2024-08-27 17:31:40</td>\n",
       "      <td>Moneycontrol</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.999225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker                                           headline  \\\n",
       "2145  ZYDUSLIFE  Stocks to Watch: Jio Financial Services, ICICI...   \n",
       "2146  ZYDUSLIFE  Brokerage Radar: United Spirits, Zydus Life ba...   \n",
       "2147  ZYDUSLIFE  डबल अपग्रेड हुआ ये Pharma Stock, ब्रोकरेज सुपर...   \n",
       "2148  ZYDUSLIFE  Hot stocks: Brokerage view on L&T Finance, Ind...   \n",
       "2149     ECLERX  This mid-cap IT party is getting lit; NIIT, Da...   \n",
       "\n",
       "              date_posted              source  \\\n",
       "2145  2024-08-28 17:31:40                mint   \n",
       "2146  2024-08-28 17:31:40        Moneycontrol   \n",
       "2147  2024-08-28 17:31:40        Zee Business   \n",
       "2148  2024-08-28 17:31:40  The Economic Times   \n",
       "2149  2024-08-27 17:31:40        Moneycontrol   \n",
       "\n",
       "                                           article_link  positive   neutral  \\\n",
       "2145  https://www.livemint.com/market/stock-market-n...  0.000061  0.999851   \n",
       "2146  https://www.moneycontrol.com/news/business/bro...  0.999534  0.000143   \n",
       "2147  https://www.zeebiz.com/hindi/stock-markets/sto...  0.000076  0.999847   \n",
       "2148  https://m.economictimes.com/markets/stocks/new...  0.000059  0.999873   \n",
       "2149  https://www.moneycontrol.com/news/business/mar...  0.999426  0.000373   \n",
       "\n",
       "      negative  compound  \n",
       "2145  0.000087 -0.000026  \n",
       "2146  0.000323  0.999211  \n",
       "2147  0.000078 -0.000002  \n",
       "2148  0.000068 -0.000010  \n",
       "2149  0.000201  0.999225  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data into DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(\"./datasets/ticker_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x108ae9870>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new table for storing article data\n",
    "\n",
    "conn.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS article_data (ticker TEXT, headline TEXT, date_posted TEXT, source TEXT, article_link TEXT, negative_sentiment FLOAT, positive_sentiment FLOAT, neutral_sentiment FLOAT, compound_sentiment FLOAT)\"\n",
    ")\n",
    "\n",
    "# insert article data into the table\n",
    "# conn.executemany(\"INSERT INTO article_data VALUES (?, ?, ?, ?, ?)\", article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    INSERT INTO article_data SELECT * FROM article_df\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"SELECT * FROM article_data\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new table for storing ticker metadata\n",
    "\n",
    "conn.execute(\n",
    "    \"CREATE or REPLACE TABLE ticker_meta (ticker TEXT, sector TEXT, industry TEXT, mCap REAL, companyName TEXT)\"\n",
    ")\n",
    "\n",
    "# insert ticker metadata into the table, this table will be replaced on every run.\n",
    "conn.executemany(\"INSERT into ticker_meta VALUES (?, ?, ?, ?, ?)\", ticker_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"SELECT * from ticker_meta limit 5\").df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
